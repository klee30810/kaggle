{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Pandas.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpZzKtapvQdX"
      },
      "source": [
        "# Text Processing : tfidf\n",
        "\n",
        "### Libray importing & etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXg1o2YVvQMQ",
        "outputId": "bd55ca3e-d25e-4a95-8595-187e8a13f0f3"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CprU9i87wBMo"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np \n",
        "from pathlib import Path\n",
        "import pandas as pd \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "import seaborn as sns\n",
        "import warnings"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_I3J6O5wl_H"
      },
      "source": [
        "rcParams['figure.figsize'] = (16, 8)\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('max_columns', 100)\n",
        "pd.set_option('display.precision', 4)\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16E8QaLnuYeo"
      },
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKFaUAegIRYP"
      },
      "source": [
        "data_dir = Path('../data/dacon-author-classification')\n",
        "feature_dir = Path('../build/feature')\n",
        "val_dir = Path('../build/val')\n",
        "tst_dir = Path('../build/tst')\n",
        "sub_dir = Path('../build/sub')\n",
        "\n",
        "trn_file = data_dir / 'train.csv'\n",
        "tst_file = data_dir / 'test_x.csv'\n",
        "sample_file = data_dir / 'sample_submission.csv'\n",
        "\n",
        "target_col = 'class'\n",
        "n_fold = 5\n",
        "n_class = 5\n",
        "seed = 42"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "algo_name = 'lr'\n",
        "feature_name = 'tfidf'\n",
        "model_name = f'{algo_name}_{feature_name}'\n",
        "\n",
        "feature_file = feature_dir / f'{feature_name}.csv'\n",
        "p_val_file = val_dir / f'{model_name}.val.csv'\n",
        "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
        "sub_file = sub_dir / f'{model_name}.csv'"
      ]
    },
    {
      "source": [
        "### Polynomial Feature Creation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54879, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "0      He was almost choking. There was so much, so m...       3\n",
              "1                 “Your sister asked for it, I suppose?”       2\n",
              "2       She was engaged one day as she walked, in per...       1\n",
              "3      The captain was in the porch, keeping himself ...       4\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...       3"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>author</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>He was almost choking. There was so much, so m...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>“Your sister asked for it, I suppose?”</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>She was engaged one day as she walked, in per...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The captain was in the porch, keeping himself ...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "trn = pd.read_csv(trn_file, index_col=0)\n",
        "print(trn.shape)\n",
        "trn.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19617, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text\n",
              "index                                                   \n",
              "0      “Not at all. I think she is one of the most ch...\n",
              "1      \"No,\" replied he, with sudden consciousness, \"...\n",
              "2      As the lady had stated her intention of scream...\n",
              "3      “And then suddenly in the silence I heard a so...\n",
              "4      His conviction remained unchanged. So far as I..."
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>“Not at all. I think she is one of the most ch...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>As the lady had stated her intention of scream...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>“And then suddenly in the silence I heard a so...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>His conviction remained unchanged. So far as I...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tst = pd.read_csv(tst_file, index_col=0)\n",
        "print(tst.shape)\n",
        "tst.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7JWMF-Wyr4u"
      },
      "source": [
        "### NLTK Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“Have mercy, gentlemen!” odin flung up his hands. “Don’t write that, anyway; have some shame. Here I’ve torn my heart asunder before you, and you seize the opportunity and are fingering the wounds in both halves.... Oh, my God!”\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "s = trn.text[4]\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /home/klee30810/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['“', 'Have', 'mercy', ',', 'gentlemen', '!', '”', 'odin', 'flung', 'up', 'his', 'hands', '.', '“', 'Don', '’', 't', 'write', 'that', ',', 'anyway', ';', 'have', 'some', 'shame', '.', 'Here', 'I', '’', 've', 'torn', 'my', 'heart', 'asunder', 'before', 'you', ',', 'and', 'you', 'seize', 'the', 'opportunity', 'and', 'are', 'fingering', 'the', 'wounds', 'in', 'both', 'halves', '....', 'Oh', ',', 'my', 'God', '!', '”']\n"
          ]
        }
      ],
      "source": [
        "tokens = word_tokenize(s)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['“',\n",
              " 'Have',\n",
              " 'mercy',\n",
              " ',',\n",
              " 'gentleman',\n",
              " '!',\n",
              " '”',\n",
              " 'odin',\n",
              " 'flung',\n",
              " 'up',\n",
              " 'his',\n",
              " 'hand',\n",
              " '.',\n",
              " '“',\n",
              " 'Don',\n",
              " '’',\n",
              " 't',\n",
              " 'write',\n",
              " 'that',\n",
              " ',',\n",
              " 'anyway',\n",
              " ';',\n",
              " 'have',\n",
              " 'some',\n",
              " 'shame',\n",
              " '.',\n",
              " 'Here',\n",
              " 'I',\n",
              " '’',\n",
              " 've',\n",
              " 'torn',\n",
              " 'my',\n",
              " 'heart',\n",
              " 'asunder',\n",
              " 'before',\n",
              " 'you',\n",
              " ',',\n",
              " 'and',\n",
              " 'you',\n",
              " 'seize',\n",
              " 'the',\n",
              " 'opportunity',\n",
              " 'and',\n",
              " 'are',\n",
              " 'fingering',\n",
              " 'the',\n",
              " 'wound',\n",
              " 'in',\n",
              " 'both',\n",
              " 'half',\n",
              " '....',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'my',\n",
              " 'God',\n",
              " '!',\n",
              " '”']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "[lemmatizer.lemmatize(t) for t in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['“',\n",
              " 'have',\n",
              " 'merci',\n",
              " ',',\n",
              " 'gentlemen',\n",
              " '!',\n",
              " '”',\n",
              " 'odin',\n",
              " 'flung',\n",
              " 'up',\n",
              " 'his',\n",
              " 'hand',\n",
              " '.',\n",
              " '“',\n",
              " 'don',\n",
              " '’',\n",
              " 't',\n",
              " 'write',\n",
              " 'that',\n",
              " ',',\n",
              " 'anyway',\n",
              " ';',\n",
              " 'have',\n",
              " 'some',\n",
              " 'shame',\n",
              " '.',\n",
              " 'here',\n",
              " 'i',\n",
              " '’',\n",
              " 've',\n",
              " 'torn',\n",
              " 'my',\n",
              " 'heart',\n",
              " 'asund',\n",
              " 'befor',\n",
              " 'you',\n",
              " ',',\n",
              " 'and',\n",
              " 'you',\n",
              " 'seiz',\n",
              " 'the',\n",
              " 'opportun',\n",
              " 'and',\n",
              " 'are',\n",
              " 'finger',\n",
              " 'the',\n",
              " 'wound',\n",
              " 'in',\n",
              " 'both',\n",
              " 'halv',\n",
              " '....',\n",
              " 'oh',\n",
              " ',',\n",
              " 'my',\n",
              " 'god',\n",
              " '!',\n",
              " '”']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "[stemmer.stem(t) for t in tokens]"
      ]
    },
    {
      "source": [
        "### Bag-of-Words feature Creation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/klee30810/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54879, 2685)\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(tokenizer=word_tokenize, stop_words=stopwords.words('english'), ngram_range=(1,2), min_df=100)\n",
        "X_cnt = vec.fit_transform(trn['text'])\n",
        "print(X_cnt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X_cnt [0, :50].todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54879, 5897) (19617, 5897)\n"
          ]
        }
      ],
      "source": [
        "vec = TfidfVectorizer(tokenizer=word_tokenize, stop_words=stopwords.words('english'), ngram_range=(1,3), min_df=50)\n",
        "X = vec.fit_transform(trn['text'])\n",
        "X_tst = vec.transform(tst['text'])\n",
        "print(X.shape, X_tst.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "X[0, :50].todense()"
      ]
    },
    {
      "source": [
        "### Logistic Regression"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54879,)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "\n",
        "y = trn.author.values\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model for CV#1\n",
            "training model for CV#2\n",
            "training model for CV#3\n",
            "training model for CV#4\n",
            "training model for CV#5\n"
          ]
        }
      ],
      "source": [
        "p = np.zeros((X.shape[0], n_class))\n",
        "p_tst = np.zeros((X_tst.shape[0], n_class))\n",
        "\n",
        "for i_cv, (i_trn, i_val) in enumerate(cv.split(X, y), 1):\n",
        "    print(f'training model for CV#{i_cv}')\n",
        "\n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(X[i_trn],y[i_trn])\n",
        "\n",
        "    p[i_val, :] = clf.predict_proba(X[i_val])            \n",
        "    p_tst += clf.predict_proba(X_tst) / n_class"
      ]
    },
    {
      "source": [
        "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p, axis=1))*100:8.4f}%')\n",
        "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p):8.4f}')"
      ],
      "cell_type": "code",
      "metadata": {},
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (CV):  76.6158%\nLog Loss (CV):   0.6800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.savetxt(p_val_file, p, fmt='%.6f', delimiter=',')\n",
        "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
      ]
    },
    {
      "source": [
        "### Submission file Creation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19617, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0  1  2  3  4\n",
              "index               \n",
              "0      0  0  0  0  0\n",
              "1      0  0  0  0  0\n",
              "2      0  0  0  0  0\n",
              "3      0  0  0  0  0\n",
              "4      0  0  0  0  0"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "sub = pd.read_csv(sample_file, index_col=0)\n",
        "print(sub.shape)\n",
        "sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0       1       2       3       4\n",
              "index                                        \n",
              "0      0.0631  0.5302  0.3155  0.0659  0.0253\n",
              "1      0.0815  0.8202  0.0032  0.0269  0.0682\n",
              "2      0.7208  0.0319  0.1174  0.0381  0.0918\n",
              "3      0.0392  0.0036  0.8465  0.0058  0.1049\n",
              "4      0.3044  0.2440  0.1450  0.1905  0.1161"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0631</td>\n      <td>0.5302</td>\n      <td>0.3155</td>\n      <td>0.0659</td>\n      <td>0.0253</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0815</td>\n      <td>0.8202</td>\n      <td>0.0032</td>\n      <td>0.0269</td>\n      <td>0.0682</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.7208</td>\n      <td>0.0319</td>\n      <td>0.1174</td>\n      <td>0.0381</td>\n      <td>0.0918</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0392</td>\n      <td>0.0036</td>\n      <td>0.8465</td>\n      <td>0.0058</td>\n      <td>0.1049</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.3044</td>\n      <td>0.2440</td>\n      <td>0.1450</td>\n      <td>0.1905</td>\n      <td>0.1161</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "sub[sub.columns] = p_tst\n",
        "sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "sub.to_csv(sub_file)"
      ]
    }
  ]
}